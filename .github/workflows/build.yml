name: Build
on:
  workflow_dispatch:
    inputs:
      onnxruntime-version:
        type: string
        description: "ONNX Runtime version (e.g. 1.18.0); fallbacks to main branch"
        default: main
env:
  GCC_VERSION: '11'
  CMAKE_VERSION: '3.28'
  PYTHON_VERSION: '3.10'
  NODE_VERSION: '18'
  XCODE_VERSION: '14.3'
  MACOSX_DEPLOYMENT_TARGET: '10.15'
jobs:
  build:
    name: Build
    runs-on: ${{ matrix.runs-on }}
    strategy:
      fail-fast: false
      matrix:
        include:
          # - target: aarch64-unknown-linux-gnu
          #   args: "-t -A aarch64 --xnnpack"
          #   static: true
          #   feature-set: train
          #   runs-on: ubuntu-22.04
          # - target: x86_64-unknown-linux-gnu
          #   args: "-t --xnnpack"
          #   static: true
          #   feature-set: train
          #   runs-on: ubuntu-22.04
          # - target: x86_64-unknown-linux-gnu
          #   args: "-t --cuda --trt --xnnpack"
          #   static: false
          #   feature-set: train,cu12
          #   cuda-version: '12.5.1'
          #   runs-on: ubuntu-22.04
          # - target: x86_64-unknown-linux-gnu
          #   args: "-t --rocm --xnnpack"
          #   static: false
          #   feature-set: train,rocm
          #   rocm: true
          #   runs-on: ubuntu-22.04
          # - target: aarch64-apple-darwin
          #   args: "-t --coreml -A aarch64 --xnnpack"
          #   static: true
          #   feature-set: train
          #   runs-on: macos-13
          # - target: x86_64-apple-darwin
          #   args: "-t --coreml --xnnpack"
          #   static: true
          #   feature-set: train
          #   runs-on: macos-13
          # - target: x86_64-pc-windows-msvc
          #   args: "-t --directml --cuda --trt --xnnpack"
          #   static: false
          #   feature-set: train,cu12
          #   cuda-version: '12.5.1'
          #   runs-on: windows-2022
          # - target: aarch64-pc-windows-msvc
          #   args: "-t -A aarch64 --directml"
          #   static: true
          #   feature-set: train
          #   runs-on: windows-2022
          # - target: x86_64-pc-windows-msvc
          #   args: "-t --directml --xnnpack"
          #   static: true
          #   feature-set: train
          #   runs-on: windows-2022
          - target: aarch64-unknown-linux-gnu
            args: "-A aarch64 --xnnpack"
            static: true
            feature-set: none
            runs-on: ubuntu-22.04
          - target: x86_64-unknown-linux-gnu
            args: "--xnnpack"
            static: true
            feature-set: none
            runs-on: ubuntu-22.04
          # - target: x86_64-unknown-linux-gnu
          #   args: "--cuda --trt --xnnpack"
          #   static: false
          #   feature-set: cu12
          #   cuda-version: '12.5.1'
          #   runs-on: ubuntu-22.04
          # - target: x86_64-unknown-linux-gnu
          #   args: "--rocm --xnnpack"
          #   static: false
          #   feature-set: rocm
          #   rocm: true
          #   runs-on: ubuntu-22.04
          - target: aarch64-apple-darwin
            args: "--coreml -A aarch64 --xnnpack"
            static: true
            feature-set: none
            runs-on: macos-13
          - target: x86_64-apple-darwin
            args: "--coreml --xnnpack"
            static: true
            feature-set: none
            runs-on: macos-13
          # - target: x86_64-pc-windows-msvc
          #   args: "--directml --cuda --trt --xnnpack"
          #   static: false
          #   feature-set: cu12
          #   cuda-version: '12.5.1'
          #   runs-on: windows-2022
          # - target: aarch64-pc-windows-msvc
          #   args: "-A aarch64 --directml"
          #   static: true
          #   feature-set: none
          #   runs-on: windows-2022
          - target: x86_64-pc-windows-msvc
            args: "--xnnpack"
            static: true
            feature-set: none
            runs-on: windows-2022
          - target: wasm32-unknown-emscripten
            args: "-W"
            static: true
            feature-set: none
            runs-on: ubuntu-22.04
    steps:
      - name: Install cross-compile tools
        if: matrix.target == 'aarch64-unknown-linux-gnu'
        run: |
          sudo apt update && sudo apt install -y gcc make gcc-11-aarch64-linux-gnu g++-11-aarch64-linux-gnu binutils-aarch64-linux-gnu
      - name: Remove unnecessary software
        if: runner.os == 'Linux'
        run: |
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL
          sudo docker image prune --all --force
      - uses: actions/checkout@v4
      - uses: pykeio/cuda-toolkit@v0.2.18
        if: matrix.cuda-version && runner.os != 'macOS'
        with:
          cuda: ${{ matrix.cuda-version }}
      - name: Install ROCm
        if: matrix.rocm && runner.os == 'Linux'
        run: |
          wget https://repo.radeon.com/amdgpu-install/6.1.1/ubuntu/jammy/amdgpu-install_6.1.60101-1_all.deb
          sudo apt install ./amdgpu-install_6.1.60101-1_all.deb -y
          DEBIAN_FRONTEND=noninteractive amdgpu-install --accept-eula -y --usecase=rocm,hiplibsdk --no-dkms
      - uses: denoland/setup-deno@v2
        with:
          deno-version: v2.x
      - name: Run builder
        run:
          deno run -A src/build.ts -v ${{ inputs.onnxruntime-version }} ${{ matrix.static && '-s' || '' }} ${{ matrix.args }}
        # env:
        #  CUDNN_URL: ${{ matrix.cuda-version && (runner.os == 'Linux' && secrets.CUDNN9_2_CUDA12_LINUX_URL || secrets.CUDNN9_2_CUDA12_WINDOWS_URL) }}
        #  TENSORRT_URL: ${{ matrix.cuda-version && (runner.os == 'Linux' && secrets.TENSORRT10_0_CUDA12_LINUX_URL || secrets.TENSORRT10_0_CUDA12_WINDOWS_URL) }}
      - uses: actions/upload-artifact@v4
        with:
          name: ortrs_${{ matrix.static && 'static' || 'dylib' }}${{ matrix.feature-set != 'none' && format('_{0}', matrix.feature-set) || '' }}-v${{ inputs.onnxruntime-version }}-${{ matrix.target }}
          path: artifact
          if-no-files-found: error
